{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4dcdc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取柏克萊書籍  書名:python  價格, 圖片\n",
    "import requests # 跟前檯小姐姐拿資料\n",
    "#如果還沒安裝bs4\n",
    "# !pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup # 這個soup 是用來解析,str 長得很像html 格式的工具 \n",
    "#如果是mac 再爬取時, 有時候會遇到 ssl 安全憑證問題 , 請幫我加入:\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d8854",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://search.books.com.tw/search/query/key/python/cat/all' #我們的問題(我們的問題,使這個小姐姐給我們一堆盒子)\n",
    "my_headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.3'  \n",
    "}\n",
    "\n",
    "response = requests.get(url, headers = my_headers)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#由於 response.text 不是json 的字典格式, 所以不能用之前的json.loads 的功能\n",
    "soup = BeautifulSoup(response.text , 'html.parser')\n",
    "type(soup)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#開始找盒子, 找盒子功能介紹:\n",
    "#功能1 find_all -找出很多個我們條件盒子\n",
    "# 舉例: 嘗試找一下大盒子\n",
    "boxs = soup.find_all('div',class_ = \"table-td\") #找到橫向最大的盒子   (品牌, 特徵1 , 特徵2.....)\n",
    "#由於我們要繼續找盒子(bs4特有的功能), 所以注意一下type要轉換為bs4的type\n",
    "len(boxs)\n",
    "\n",
    "# 功能2 find  - 找出一個我們條件的盒子(如果事實上有很多個相同條件盒子,也只會回傳第一個盒子)\n",
    "box_a   = boxs[19].find('a',target=\"_blank\") \n",
    "box_img = box_a.find('img',class_ = 'b-lazy') #b-lazy ,b-loaded 兩種屬性\n",
    "box_img #找到我們要的img 盒子\n",
    "\n",
    "#功能3 get  -得到當下盒子裡面其他指定的特徵\n",
    "img_link= box_img.get('data-src')\n",
    "title   = box_a.get('title')\n",
    "print('圖片連結:',img_link)\n",
    "print('產品title',title)\n",
    "\n",
    "\n",
    "#功能4 text -得到當下盒子內的紙條\n",
    "price_box = boxs[19].find('ul',class_ = 'price')\n",
    "p_list = price_box.find_all('b')\n",
    "discount = p_list[0].text\n",
    "price    = p_list[1].text\n",
    "\n",
    "print(f'產品折扣:{discount}')\n",
    "print(f'產品價格:{price}')\n",
    "\n",
    "\n",
    "# 如果想要下載圖片, 使用urllib的功能包\n",
    "import urllib.request\n",
    "import os\n",
    "if not os.path.exists('./imgs'):\n",
    "    os.makedirs('./imgs')\n",
    "    \n",
    "urllib.request.urlretrieve(img_link,'./imgs/1.jpg')\n",
    "# for each_box in windoes:\n",
    "#     a_box = each_box.find('a')\n",
    "#     title= a_box.get('title')\n",
    "#     link = 'https:'+ a_box.get('href')\n",
    "#     print(title)\n",
    "#     print(link)\n",
    "#     print('=============')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#整理一下, 圖片連結, 商品名稱 ,價格\n",
    "print('圖片連結:',img_link)\n",
    "print('產品title',title)\n",
    "print('商品價格:',price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8786e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://addons.books.com.tw/G/prod/comingsoon_rec.gif&w=374&h=374 2x\n",
      "商品title: Python\n",
      "商品價格: 1120\n",
      "=====================第1個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://addons.books.com.tw/G/prod/comingsoon_rec.gif&w=374&h=374 2x\n",
      "商品title: Python\n",
      "商品價格: 1013\n",
      "=====================第2個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/F01/738/69/F017386990.jpg&w=374&h=374&v=5fa8fffc 2x\n",
      "商品title: python\n",
      "商品價格: 1015\n",
      "=====================第3個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://addons.books.com.tw/G/prod/comingsoon_rec.gif&w=374&h=374 2x\n",
      "商品title: Python\n",
      "商品價格: 688\n",
      "=====================第4個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/F01/360/97/F013609706.jpg&w=374&h=374&v=5dc31292 2x\n",
      "商品title: Python\n",
      "商品價格: 320\n",
      "=====================第5個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://addons.books.com.tw/G/prod/comingsoon_rec.gif&w=374&h=374 2x\n",
      "商品title: Python\n",
      "商品價格: 403\n",
      "=====================第6個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://addons.books.com.tw/G/prod/comingsoon_rec.gif&w=374&h=374 2x\n",
      "商品title: Python\n",
      "商品價格: 1575\n",
      "=====================第7個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/F01/281/69/F012816992.jpg&w=374&h=374&v=5dc34398 2x\n",
      "商品title: Python\n",
      "商品價格: 640\n",
      "=====================第8個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/F01/245/53/F012455388.jpg&w=374&h=374&v=5dc4544b 2x\n",
      "商品title: Python\n",
      "商品價格: 408\n",
      "=====================第9個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/F01/239/58/F012395812.jpg&w=374&h=374&v=5dc45364 2x\n",
      "商品title: Python\n",
      "商品價格: 1180\n",
      "=====================第10個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/F01/181/72/F011817239.jpg&w=374&h=374&v=5dc24243 2x\n",
      "商品title: Python\n",
      "商品價格: 1197\n",
      "=====================第11個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://addons.books.com.tw/G/prod/comingsoon_rec.gif&w=374&h=374 2x\n",
      "商品title: Python\n",
      "商品價格: 525\n",
      "=====================第12個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://addons.books.com.tw/G/prod/comingsoon_rec.gif&w=374&h=374 2x\n",
      "商品title: Python\n",
      "商品價格: 770\n",
      "=====================第13個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/093/32/0010933211.jpg&w=374&h=374&v=62f388b6 2x\n",
      "商品title: Python - 最強入門邁向數據科學之路：王者歸來(全彩印刷第三版)【首刷獨家限量贈品-程式語言濾掛式咖啡包】\n",
      "商品價格: 853\n",
      "=====================第14個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/093/21/0010932115.jpg&w=374&h=374&v=62e26537 2x\n",
      "商品title: 從零開始使用Python打造投資工具\n",
      "商品價格: 514\n",
      "=====================第15個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/092/96/0010929648.jpg&w=374&h=374&v=62c412ce 2x\n",
      "商品title: Python操作Excel：最強入門邁向辦公室自動化之路 王者歸來\n",
      "商品價格: 537\n",
      "=====================第16個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/092/92/0010929209.jpg&w=374&h=374&v=62bc29f9 2x\n",
      "商品title: Python初學特訓班(第五版)：從快速入門到主流應用全面實戰(附500分鐘影音教學/範例程式)\n",
      "商品價格: 379\n",
      "=====================第17個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/092/25/0010922575.jpg&w=374&h=374&v=625d3dac 2x\n",
      "商品title: Python 教學手冊\n",
      "商品價格: 514\n",
      "=====================第18個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/093/26/0010932677.jpg&w=374&h=374&v=62ea4e36 2x\n",
      "商品title: Python 資料科學實戰教本：爬蟲、清理、資料庫、視覺化、探索式分析、機器學習建模，數據工程一次搞定!\n",
      "商品價格: 537\n",
      "=====================第19個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/093/36/0010933669.jpg&w=374&h=374&v=62fb71c4 2x\n",
      "商品title: Python：量化交易Ta-Lib技術指標139個活用技巧\n",
      "商品價格: 484\n",
      "=====================第20個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/093/06/0010930615.jpg&w=374&h=374&v=62cff036 2x\n",
      "商品title: Python：股票×ETF量化交易回測102個活用技巧\n",
      "商品價格: 450\n",
      "=====================第21個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/092/59/0010925961.jpg&w=374&h=374&v=628b6235 2x\n",
      "商品title: 一步到位!Python 程式設計-最強入門教科書 第三版\n",
      "商品價格: 498\n",
      "=====================第22個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/092/50/0010925009.jpg&w=374&h=374&v=628b703b 2x\n",
      "商品title: 零基礎入門的Python自動化投資：10年操盤手團隊量化通，教你從零開始學程式交易，讓你輕鬆選股、判斷買賣時機，精準獲利\n",
      "商品價格: 356\n",
      "=====================第23個box商品爬取完成================================\n",
      "圖片連結: https://im1.book.com.tw/image/getImage?i=https://www.books.com.tw/img/001/092/61/0010926182.jpg&w=374&h=374&v=629f36ba 2x\n",
      "商品title: Keras大神歸位：深度學習全面進化!用 Python 實作CNN、RNN、GRU、LSTM、GAN、VAE、Transformer\n",
      "商品價格: 948\n",
      "=====================第24個box商品爬取完成================================\n"
     ]
    }
   ],
   "source": [
    "#知道了上面所有功能, 重新爬取第一頁的內容\n",
    "import time\n",
    "url = 'https://search.books.com.tw/search/query/key/python/cat/all' #我們的問題(我們的問題,使這個小姐姐給我們一堆盒子)\n",
    "my_headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.3'  \n",
    "}\n",
    "\n",
    "response = requests.get(url, headers = my_headers)\n",
    "response.text\n",
    "soup = BeautifulSoup(response.text , 'html.parser')\n",
    "boxs = soup.find_all('div',class_ = \"table-td\")\n",
    "boxs # 有很多商品box\n",
    "for idx,box in enumerate(boxs):\n",
    "    box_a   = box.find('a',target=\"_blank\")\n",
    "    box_img = box_a.find('img')\n",
    "    img_link = box_img.get('data-srcset')\n",
    "    title    = box_a.get('title')\n",
    "    \n",
    "    price_box = box.find('ul',class_ = 'price')\n",
    "    p_list = price_box.find_all('b')[-1]\n",
    "    price    = p_list.text\n",
    "    print('圖片連結:',img_link)\n",
    "    print('商品title:',title)\n",
    "    print('商品價格:',price)\n",
    "    print(f'=====================第{idx+1}個box商品爬取完成================================')\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70dbd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "======這頁(1)內容爬取完成了,休息8秒========\n",
      "偵測到錯誤\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32480\\3688633920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_headers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf22\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32480\\3688633920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'偵測到錯誤'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 爬取所有頁面資料\n",
    "import time \n",
    "import random\n",
    "title_list = []\n",
    "price_list = []\n",
    "img_ink_list = []\n",
    "\n",
    "page_from = 1\n",
    "while page_from<=5:\n",
    "    try:\n",
    "        rst = random.randint(5,10)\n",
    "        url =  'https://search.books.com.tw/search/query/cat/all/sort/1/v/0/spell/3/ms2/ms2_1/page/'+str(page_from)+'/key/python'\n",
    "        my_headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'  \n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers = my_headers)\n",
    "        response.text\n",
    "        soup = BeautifulSoup(response.text , 'html.parser')\n",
    "        boxs = soup.find_all('div',class_ = \"table-td\")\n",
    "        boxs # 有很多商品box\n",
    "        print(boxs)\n",
    "        for idx,box in enumerate(boxs):\n",
    "            box_a   = box.find('a',target=\"_blank\")\n",
    "            box_img = box_a.find('img')\n",
    "            img_link = box_img.get('data-srcset')\n",
    "            title    = box_a.get('title')\n",
    "\n",
    "            price_box = box.find('ul',class_ = 'price')\n",
    "            p_list = price_box.find_all('b')[-1]\n",
    "            price    = p_list.text\n",
    "            print('圖片連結:',img_link)\n",
    "            print('商品title:',title)\n",
    "            print('商品價格:',price)\n",
    "    #         print(f'=====================第{idx+1}個box商品爬取完成================================')\n",
    "            title_list.append(title)\n",
    "            price_list.append(price)\n",
    "            img_ink_list.append(img_link)\n",
    "        print(f'======這頁({page_from})內容爬取完成了,休息{rst}秒========')\n",
    "        page_from = page_from+1\n",
    "        \n",
    "        time.sleep(rst)\n",
    "    except:\n",
    "        print('偵測到錯誤')\n",
    "        time.sleep(5)\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cd619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#把爬取下來的數據做成表格:\n",
    "# title_list\n",
    "# price_list\n",
    "# img_ink_list\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "df = pd.DataFrame(columns = ['title','price','img_link'])\n",
    "df['title']    = title_list\n",
    "df['price']    = price_list\n",
    "df['img_link'] = img_ink_list\n",
    "df\n",
    "#爬完資料,可以存到我們想要的資料夾\n",
    "if not os.path.exists('./csv_file'):\n",
    "    os.makedirs('./csv_file')\n",
    "df.to_csv('./csv_file/my_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c85fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df61f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#下載所有圖片\n",
    "if not os.path.exists('./imgs'):\n",
    "    os.makedirs('./imgs')\n",
    "n = 1\n",
    "for link in df['img_link']:\n",
    "    link=link.split(' ')\n",
    "    urllib.request.urlretrieve(link[0],f'./imgs/{n}.jpg')\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用情境: 我只要找有關爬蟲的python書,以及股票爬蟲的書籍\n",
    "key_word_1 = 'Python'\n",
    "key_word_2 = '股票'\n",
    "target_row = []\n",
    "for row,s in enumerate(df['title']):\n",
    "    if key_word_1 in s and key_word_2 in s:\n",
    "        target_row.append(row)\n",
    "print('與我下的關鍵字有先關的數據位子:',target_row)\n",
    "target_df = df.iloc[target_row,:]\n",
    "target_df.to_csv('./csv_file/my_target_file.csv')\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c161b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#把我們感興趣的df price 處理成可以被畫圖的數字型態\n",
    "def str2int(data):\n",
    "    return int(data)\n",
    "    \n",
    "target_df['price'] = target_df['price'].apply(str2int)\n",
    "price_list = target_df['price'].values.tolist()\n",
    "price_list_sorted = sorted(price_list)\n",
    "price_list_sorted\n",
    "plt.hist(price_list_sorted,  #hist: 是針對1維數據做記數座圖  #bar:針對2為數據化柱狀圖\n",
    "        bins=50,\n",
    "        color = 'green',\n",
    "        label = 'target_price')\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('numbers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用需求, 用一句話,搜索整個df 找出最相關的那幾本書\n",
    "import difflib\n",
    "def str_similar(s1,s2):\n",
    "    sim = difflib.SequenceMatcher(None , s1,s2)\n",
    "    ratio = sim.quick_ratio()\n",
    "    return ratio \n",
    "\n",
    "\n",
    "sentience_key = 'python 資料科學,教你手把手爬取股票分析'\n",
    " \n",
    "ratio_list =[]\n",
    "for s in df['title']:\n",
    "    ratio = str_similar(s,sentience_key)\n",
    "    ratio_list.append(ratio)\n",
    "ratio_list\n",
    "df['ratio']=ratio_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a977536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targt_row = []\n",
    "for row,i in enumerate(df['ratio']):\n",
    "    if i >0.4:\n",
    "        target_row.append(row)\n",
    "target_row\n",
    "taraget_df = df.iloc[target_row,:]\n",
    "taraget_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9acb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c168aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#開始包裝上述爬蟲的功能, 包成一個class 方便之後調用\n",
    "# 爬取所有頁面資料\n",
    "import time \n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "class books_webcrl:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def make_dir(self,path): #偷偷註記 path= './img'....\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "\n",
    "    def webcrl(self,my_key,page_from,target_page):\n",
    "        title_list = []\n",
    "        price_list = []\n",
    "        img_ink_list = []\n",
    "        while page_from<=target_page:\n",
    "            try:\n",
    "                rst = random.randint(10,25)\n",
    "                url =  'https://search.books.com.tw/search/query/cat/all/sort/1/v/0/spell/3/ms2/ms2_1/page/'+str(page_from)+'/key/'+my_key\n",
    "                my_headers = {\n",
    "                    'Host': 'search.books.com.tw',\n",
    "                    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.3'  \n",
    "                }\n",
    "                response = requests.get(url, headers = my_headers)\n",
    "                response.text\n",
    "                soup = BeautifulSoup(response.text , 'html.parser')\n",
    "                windoes = soup.find_all('table',class_ = \"table-searchlist clearfix\")\n",
    "                windows_bs4 = windoes[0]\n",
    "                boxs = windows_bs4.find_all('tbody')\n",
    "                boxs # 有很多商品box\n",
    "                for idx,box in enumerate(boxs):\n",
    "                    box_a   = box.find('a',target=\"_blank\")\n",
    "                    box_img = box_a.find('img')\n",
    "                    img_link = box_img.get('data-srcset')\n",
    "                    title    = box_a.get('title')\n",
    "\n",
    "                    boxs_price = box.find_all('td')[2]\n",
    "                    prices = boxs_price.find('ul', class_=\"list-nav clearfix\")\n",
    "                    boxs_strong = prices.find_all('strong')\n",
    "                    price = boxs_strong[-1].text\n",
    "\n",
    "                    title_list.append(title)\n",
    "                    price_list.append(price)\n",
    "                    img_ink_list.append(img_link)\n",
    "                print(f'======這頁({page_from})內容爬取完成了,休息{rst}秒========')\n",
    "                page_from = page_from+1\n",
    "\n",
    "                time.sleep(rst)\n",
    "            except:\n",
    "                print('偵測到錯誤')\n",
    "                time.sleep(5)\n",
    "                pass\n",
    "        return title_list , price_list , img_ink_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = books_webcrl()\n",
    "B.make_dir('./my_imgs')\n",
    "title_list , price_list , img_ink_list  = B.webcrl('料理',1,3)\n",
    "#list都有了 開始創建df 做我想要的篩選\n",
    "df = pd.DataFrame(columns = ['title','price','img_link'])\n",
    "df['title']    = title_list\n",
    "df['price']    = price_list\n",
    "df['img_link'] = img_ink_list\n",
    "df\n",
    "#爬完資料,可以存到我們想要的資料夾\n",
    "if not os.path.exists('./csv_file'):\n",
    "    os.makedirs('./csv_file')\n",
    "df.to_csv('./csv_file/my_file.csv')\n",
    "\n",
    "key_word_1 = '美食'\n",
    "key_word_2 = '料理'\n",
    "target_row = []\n",
    "for row,s in enumerate(df['title']):\n",
    "    if key_word_1 in s and key_word_2 in s:\n",
    "        target_row.append(row)\n",
    "print('與我下的關鍵字有先關的數據位子:',target_row)\n",
    "target_df = df.iloc[target_row,:]\n",
    "target_df.to_csv('./csv_file/my_target_file.csv')\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4838dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a6bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ba7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d74b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec658356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656bcbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0aa688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1389c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
